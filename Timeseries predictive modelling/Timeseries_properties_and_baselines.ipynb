{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Predictive modelling with timeseries<center>\n",
    "# <center>Baselines, stationarity and decomposition <center>\n",
    "\n",
    "![Image](images/timeseries.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import adf_test\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# jupyter lab configs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as sta\n",
    "sta.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Baselines \n",
    "\n",
    "The simplest forecasts one can do using univariate datasets are:\n",
    "* 1. Average\n",
    "* 2. Naive\n",
    "* 3. Seasonal Naive\n",
    "* 4. Moving Average\n",
    "    * a. normal\n",
    "    * b. cumulative\n",
    "    \n",
    "![Image](images/baselines.png) \n",
    "\n",
    "*Source: Hyndman and Athanasopoulos. www.otexts.com/fpp2/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of trend data - wine sales\n",
    "wine = pd.read_csv('datasets/wine_trend.csv')\n",
    "\n",
    "# example of seasonal data - daily temperature\n",
    "temperature = pd.read_csv('datasets/temperature_seasonal.csv')\n",
    "temperature.set_index('date', drop=True, inplace=True)\n",
    "\n",
    "# load a nice example for decomposition - production of electrical equipments\n",
    "ele_df = pd.read_csv('datasets/elecequip.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive methods and averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which baseline worked best in the case of trend data? Which one was best for seasonal data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average smoothing\n",
    "### Understand the difference between `rolling` windows and `expanding` windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate a **moving average** and a **cumulative moving average** using the methods from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_df['ma_5'] = ele_df.loc[:,'value'].rolling(window=2).mean()\n",
    "ele_df['ma_10'] = ele_df.loc[:,'value'].rolling(window=20).mean()\n",
    "ele_df['ma_exp'] = ele_df.loc[:,'value'].expanding().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plt.figure(figsize=(16,8))\n",
    "p = plt.plot(ele_df['ma_5'], label='Moving average - 2 steps')\n",
    "p = plt.plot(ele_df['ma_10'], label='Moving average - 20 steps')\n",
    "p = plt.plot(ele_df['ma_exp'], label='Cumulative moving average')\n",
    "p = plt.plot(ele_df['value'], label='Original')\n",
    "p = plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Time series Decomposition\n",
    "\n",
    "### What is the data made of?  ðŸ¤”\n",
    "\n",
    "Time series can be better analysed if we know how each of its components behave.  \n",
    "Typically, a time series  has 3 components:  \n",
    "* `S` as the seasonal component  \n",
    "* `T` as the trend component\n",
    "* `R` as a residual component\n",
    "\n",
    "If we consider that these components *add to each other*, the decomposition is said *additive*. \n",
    "Thus, in **additive decomposition** we have:  \n",
    "> y(t) = S(t) + T(t) + R(t)  \n",
    "\n",
    "And in **multiplicative decomposition** we have: \n",
    "> y(t) = S(t) * T(t) * R(t)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Decomposition of the Equipments dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ele_df['value'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run the additive decomposition**  \n",
    "\n",
    "The function `seasonal_decompose()` from `statsmodels` is very helpful:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonal_decompose(ele_df['value'], model='additive', period=12).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the actual numbers coming from the decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = seasonal_decompose(ele_df['value'], model='additive', period=12)\n",
    "decomposed_series = pd.concat([result.observed, result.seasonal, result.trend, result.resid], axis=1)\n",
    "decomposed_series.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the data stationary?  ðŸ¤”\n",
    "\n",
    "Stationarity means your time series does not have any `trend` or `seasonality`. Stationary time series will have no predictable patterns in the long-term. They will be very important in ARIMA, for example.\n",
    "A commom method to investigate this is with the  **Augmented Dickey-Fuller Test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Check if the wine data is stationary. If it is not, \n",
    "try with differencing and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data is stationary\n",
    "adf_test(wine.wine_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Differencing \n",
    "### (will be super important in ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the ADF-test above show that the wine time series is non-stationary.  \n",
    "Some methods will require that the data is stationary. We can still try to adjust it by using **differencing**.\n",
    ">**Differencing** is the difference between consecutive observations. It reduces (or eliminates) trend and seasonality.\n",
    "\n",
    "This procedure can be done quickly with the method `diff()` from library `statsmodels.tsa`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the behavior of `diff()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.tools import diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [20, 20, 20]\n",
    "diff(test)\n",
    "\n",
    "test = [20, 40, 60]\n",
    "diff(test)\n",
    "\n",
    "test = [40, 45, 34, 32, 41, 34, 41]\n",
    "diff(test)\n",
    "np.mean(diff(test))\n",
    "\n",
    "test = [40, 45, 34, 32, 41, 34, 41]\n",
    "diff(test, k_diff=2)\n",
    "np.mean(diff(test, k_diff=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['sales_diff'] = diff(wine['wine_sales'], k_diff=1)\n",
    "wine['sales_diff'].plot()\n",
    "adf_test(wine['sales_diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the daily sales of one of Rossman's stores (Store 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('datasets/rossman_train.csv')\n",
    "stores = pd.read_csv('datasets/rossman_store.csv')\n",
    "\n",
    "# join store features into the sales df\n",
    "sales = pd.merge(sales, stores, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(sales[sales.Store==1], x=\"Date\", y=\"Sales\", color='DayOfWeek', width=800, height=500 )\n",
    "fig = fig.add_trace(go.Line(x=sales.loc[sales.Store==1, 'Date'], y=sales[sales.Store==1].Sales, mode='lines'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look in more detail to 2 or 3 weeks: Do you see any repeating patterns?\n",
    "\n",
    "* The stores are closed sundays\n",
    "* Sales every mondays tend to be higher than the other business days\n",
    "\n",
    "**Overall** we see a cycle of 7 days in the sales -> **seasonality**   \n",
    "How does that translate into autocorrelation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "title = 'Autocorrelation - Daily Sales'\n",
    "# set the number of time steps to consider in the calculation\n",
    "lags = 30 \n",
    "plot_acf(sales[sales.Store==1].Sales, title=title, lags=lags);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the ACF plot\n",
    "\n",
    "* Autocorrelation with itself is always 1 \n",
    "* The shaded area indicates the 95% confidence intervals for the **null hypothesis** that the autocorrelation with that specific time lag is, in fact, zero.\n",
    "* Thus, in the example above, the autocorelation with time lag of 7, 14, 21 and so on, is in the order of ~62%. If we reject the null hypothesis, there's very small probability (<= 5%) of making a **Type I error**\n",
    "* We can affirm that the daily sales of the Rossman store 1 has (strong) seasonal component, with a cycle of 7 days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation plots (ACF) and stationarity\n",
    "\n",
    "The ACF plots can be used as a diagnostic tool, they help to understand if the data is stationary.  \n",
    ">For a stationary time series, the ACF will drop to zero relatively quickly, while the ACF of non-stationary data decreases slowly.  \n",
    "(Hyndman and Athanasopoulos 2018)\n",
    "\n",
    "\n",
    "The plots below show the autocorrelation existing in the `wine` dataset, where we can see a significant positive autocorrelation\n",
    "with lags 1 to 3 (first plot). Then, after applying a one-order differencing to the data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = 'Autocorrelation - wine sales before diff'\n",
    "lags = 30\n",
    "p = plot_acf(wine['wine_sales'],title=title,lags=lags);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = 'Autocorrelation - after diff'\n",
    "lags = 30\n",
    "p = plot_acf(wine.loc[1:, 'sales_diff'], title=title,lags=lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://www.freepik.com/vectors/business'>Business vector created by freepik - www.freepik.com</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
