{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICS Applied to data science\n",
    "\n",
    "## Exercises PART 2: Inferential statistics, effect sizes and power tests\n",
    "\n",
    "\n",
    "<img align=\"center\" width=\"800\"  src=\"../images/inferential.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "from numpy.random import seed, randn\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "#%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import t, norm\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.stats import power\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# jupyter lab configs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# precision options\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "%precision 4\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing with inferential statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your own t-test for two independent samples and calculate the p-value of the statistic.  \n",
    "\n",
    ">The corresponding p-value of the **calculated t statistic** can be obtained using the cumulative distribution function of the **t-distribution** (look at `stats.t.cdf(t_calc, df)`, where t_calc is the statistic, and df is the degrees of freedom, which is the number of observations -1).\n",
    "\n",
    "The critical value of `t` for a given alpha and degrees of freedom can be obtained using for example `stats.t.ppf(0.95,df=10)`\n",
    "\n",
    "![Image](../images/ttest.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_ttest(a, b):\n",
    "    # \n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    return t, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the `t-critical`, or the threshold \n",
    "\n",
    "What is the t-critical for a sample size of 10, and alpha of 95%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.ppf(0.90, df=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See if you find a similar probability, for this t-critical:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.cdf(1.3721836411102863, df=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other examples:\n",
    "What is the t-critical for a sample size of 50 and alpha of 95%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.ppf(0.95, df=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the critical t-value changes depending on the sample size. The logic is that, the samller the sample size, the larger the difference between means needs to be, to be considered as significant.    \n",
    "What is the t-critical for a sample size of 5 and alpha of 95%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.ppf(0.95, df=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the probability associated with the `t-value` you calculated using the formula above  \n",
    "\n",
    "For example, if the t statistic of your test is 1.6, and you had 10 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-stats.t.cdf(1.6, df=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing - Comparing two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('datasets/rossman_train.csv')\n",
    "stores = pd.read_csv('datasets/rossman_store.csv')\n",
    "\n",
    "# join store features into the sales df\n",
    "sales = pd.merge(sales, stores, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby([ 'Assortment'])['Store'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store_a = sales[(sales.Assortment=='a')&(sales.Open==1)&(sales.Sales>0)].Sales.head(15)\n",
    "sales_store_c = sales[(sales.Assortment=='c')&(sales.Open==1)&(sales.Sales>0)].Sales.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store_a.describe()\n",
    "sales_store_c.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a T-test, compare these 15 samples of Store A and Store C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(sales_store_a, sales_store_c, equal_var = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above `statistic` was obtained using the formula above (aka `t-calc`, and the `pvalue` was obtained using the cumulative distribution function of the T statistic**. You can check doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.cdf(-3.42248872836309, df=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store_a.plot.hist(bins=30)\n",
    "sales_store_c.plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = qqplot(np.sqrt(sales_store_a), line='s')\n",
    "r = qqplot(sales_store_c, line='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing in linear models  \n",
    "\n",
    "In linear models, given generically as `y = a + bx`, we are testing two hypothesis.  \n",
    "\n",
    "* In a OLS model (ordinary-least-squares) we are trying to find a model that **minimizes significantly** the variance in the data, compared to the simplest model (**the mean**).\n",
    "* The `p-value` associated with the F-test statistic is the probability of finding an R-squared as big or bigger, given that the null hypothesis is true; \n",
    "* The second hypothesis is that the intercept (or constant) **a** and/or the feature coefficients (like **b**) are statistically different from zero.  \n",
    "\n",
    "Let's load some data and try out:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Boston house prices data\n",
    "from sklearn.datasets import load_boston\n",
    "dt = load_boston(return_X_y=False)\n",
    "df = pd.DataFrame(data = np.c_[dt['data'],dt['target']])\n",
    "df.columns = np.append(dt['feature_names'], 'MED_VALUE')\n",
    "df.drop(['B', 'LSTAT'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Influcence of landscape and demography in house prices in Boston**  \n",
    "\n",
    "**TARGET**  \n",
    "`MEDV` Median value of owner-occupied homes in thousands\n",
    "\n",
    "**POSSIBLE FACTORS**  \n",
    "`CRIM` per capita crime rate by town    \n",
    "`NOX` nitric oxides concentration (parts per 10 million)   \n",
    "`RM` average number of rooms per dwelling    \n",
    "`DIS` weighted distances to five Boston employment centres     \n",
    "`RAD` index of accessibility to radial highways    \n",
    "`TAX` full-value property-tax rate per $10,000     \n",
    "`PTRATIO` pupil-teacher ratio by town    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(df[['CRIM', 'ZN', 'INDUS']], prepend=False)\n",
    "y = df['MED_VALUE']\n",
    "\n",
    "# Fit and summarize OLS model\n",
    "mod = sm.OLS(y, X).fit()\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's a `p-value` associated with the F-test statistic. What does it mean? What is the null hypothesis being tested here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's a `p-value` associated with every coefficient in the model. What does it mean? What is the null hypothesis here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect sizes and Power tests  \n",
    "\n",
    "![Image](../images/power.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of inference tests can be statistically significant but trivial (for example, \n",
    "\n",
    "Commom measures of the **size of an effect** are:\n",
    "* The diference between samples expressed in a standardized way\n",
    "* Correlation coefficients\n",
    "* R-square: \n",
    "\n",
    "### Cohens's D as a measure of effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    " \n",
    "def cohen_d(d1, d2):\n",
    "    \"\"\"Calculate Cohen's d for two independent samples\"\"\"\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples - Which variance (biased or unbiased) is being used here?\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # seed random number generator\n",
    "seed(3)\n",
    "# prepare data\n",
    "sample1 = 10 * randn(100) + 105\n",
    "sample2 = 10 * randn(100) + 100\n",
    "# calculate cohen's d\n",
    "d = cohen_d(sample1, sample2)\n",
    "print('Mean of sample 1: %.3f' % np.mean(sample1), '| Mean of sample 2: %.3f' % np.mean(sample2))\n",
    "print('The observed effect size is (= difference):', np.mean(sample1)- np.mean(sample2))\n",
    "print('the standardized effect size is (Cohens d): %.3f' % d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POWER tests and data science\n",
    "## Using power tests to design A/B tests\n",
    "\n",
    "**With the library `statsmodels` use this method for a 2-sample test**\n",
    "\n",
    "<code>\n",
    "from statsmodels.stats import power  \n",
    "power.tt_ind_solve_power(effect_size=None, nobs1=None, alpha=None, power=None, ratio=1.0, alternative='two-sided')  </code> \n",
    "\n",
    "\n",
    "* You can solve for one of the desired parameters `effect_size`, `nobs1`, `alpha`, or `power`, and you have to provide a value for the other 3.\n",
    "\n",
    "Here `effect size` means the standardized effect size, i. e., the diference between the two means divided by the standard deviation.   \n",
    "> An standardized effect size of 1 means that the average of one model is 1 standard deviation greater/lower than the average of the other. In other words, if RMSE of model A is 70, and the pooled standard deviation is 10, the RMSE of model B must be 80.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B test example\n",
    "![Image](../images/abtesting.png)  \n",
    "I have two models predicting the daily demand of the top-seller product. One is a Random forest and the other one, new, is a XGBoost.  \n",
    "Before replacing the old model, which is currently in production, I need to show my team that the new model is (statistically) **significantly better** than the old model.  \n",
    "### How would you plan this A/B test?  \n",
    "\n",
    "\n",
    "Suppose you compared the performance of two models during 20 days (`nobs1`=40 because there's 2 models).\n",
    "\n",
    "What is the number of samples `nobs1` required to detect an effect size of 1, given alpha=0.05 and power of 0.8?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"the number of required samples is\"\n",
    "power.tt_ind_solve_power(effect_size=1, nobs1=None, alpha=0.05, power=0.80, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret the number above?  \n",
    "it means that, if the effect size is 1, you would have neeed only 16 observations to detect the effect 🎉🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the test above considered a two-sided test, meaning the \"new\" model could be either 1 standard deviation better or worse than the current model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.tt_ind_solve_power(effect_size=1, nobs1=None, alpha=0.05, power=0.80, ratio=1.0, alternative='larger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, your manager says you only have 10 days to test your model before making a decision.  \n",
    "What would be the minimum effect size that you can detect with 80% power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"The minimum effect size possible to detect in 10 days is\"\n",
    "power.tt_ind_solve_power(effect_size=None, nobs1=20, alpha=0.05, power=0.8, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say that during model development you noticed that, for the test dataset, the old model (A) had an RMSE of 200, the new model (B) had an RMSE of 1. So you more or less expect the model B to be better (lower RMSE) than model A by  0.5 standard deviations. If you only can run the A/B test for 10 days, what will be the probability of detecting this effect (i. e., what will be the **POWER**)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"the power of this test is\"\n",
    "power.tt_ind_solve_power(effect_size=0.5, nobs1=20, alpha=0.05, power=None, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorry! there's only 34% probability that you'll detect an effect in 10 days.  \n",
    "Can you run the A/B test for longer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"now the power of this test is\"\n",
    "power.tt_ind_solve_power(effect_size=0.5, nobs1=100, alpha=0.05, power=None, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"What would be the minimum effect size that you can detect with 80% power?\"\n",
    "power.tt_ind_solve_power(effect_size=None, nobs1=10, alpha=0.05, power=0.8, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.tt_ind_solve_power(effect_size=1, nobs1=None, alpha=0.05, power=0.80, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we want to have more power in the test? (increase to 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.tt_ind_solve_power(effect_size=1, nobs1=100, alpha=0.05, power=None, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.tt_ind_solve_power(effect_size=0.5, nobs1=30, alpha=0.05, power=None, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphics from http://www.luminousmen.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
