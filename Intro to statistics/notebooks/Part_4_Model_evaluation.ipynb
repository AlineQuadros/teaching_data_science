{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICS Applied to data science\n",
    "\n",
    "## Exercises PART 4: Model Evaluation with statistical tests\n",
    "\n",
    "Model Evaluation is a crucial part of the **Proof-of-concept** stage. It also usually takes quite a long time because it's mainly a trial-and-error cycle. You start with the simplest model and iterate through many kinds of analysis until you can say you found the best model possible.\n",
    "\n",
    "**Simple question during model evaluation:** \n",
    "I'm training a model to predict the daily sales of PARFUM and MAKE_UP.  \n",
    "The overall error (I chose the metric MAE) of the model is 305 orders per day. But when analized the MAE by clusters, I got 270 (s.d.=23) for PARFUM and 338 (s.d.=80) for MAKE-UP. Is this model statistically performing worse for MAKE_UP? How do you answer this question? \n",
    "\n",
    "![Image](../images/data_1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import power\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline\n",
    "# jupyter lab configs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get familiar with Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of available built-in datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(sm.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of model evaluation \n",
    "\n",
    "### We'll use the Rossman dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../../timeseries predictive modelling/datasets/rossman_train.csv')\n",
    "stores = pd.read_csv('../../timeseries predictive modelling/datasets/rossman_store.csv')\n",
    "\n",
    "# join store features into the sales df\n",
    "sales = pd.merge(sales, stores, on='Store', how='left')\n",
    "\n",
    "# a bit of cleaning\n",
    "sales = sales[(sales.Open==1)&(sales.Sales>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby(['Store']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('datasets/rossman_test.csv')\n",
    "test['Date'].min(), test['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "sales.dropna(inplace=True)\n",
    "X = sales[['DayOfWeek', 'StoreType', 'Assortment', 'CompetitionDistance', 'Promo2', 'Promo']].copy()\n",
    "X = pd.concat([X, pd.get_dummies(X[['StoreType', 'Assortment']], prefix=['type', 'assortment'])], axis=1)\n",
    "X.drop(columns=['StoreType', 'Assortment'], inplace=True)\n",
    "X.head()\n",
    "\n",
    "y = sales.Sales.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X[['CompetitionDistance','Promo', 'Promo2', 'type_a', 'type_c', 'type_d', 'assortment_a', 'assortment_c']]\n",
    "X = X[[ 'Promo', 'type_a', 'type_c', 'type_d', 'assortment_a', 'assortment_c']]\n",
    "y = sales.Sales\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "\n",
    "# Regression metrics\n",
    "metrics.mean_absolute_error(y_test, y_pred) \n",
    "#metrics.mean_squared_error(y_test, y_pred) \n",
    "#metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look in more detail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df = pd.concat([X_test, y_test, pd.Series(y_pred, index=y_test.index, name='y_pred')], axis=1)\n",
    "errors_df['Abs_error'] = np.absolute(errors_df.Sales - errors_df.y_pred)\n",
    "\n",
    "agg_dict = {'Abs_error' : ['mean', 'std']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df.groupby([ 'Promo',  'type_a', 'type_c', 'type_d', 'assortment_a', 'assortment_c']).agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use a T-test to compare sales of stores with and without the `promo` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupa = errors_df[(errors_df.assortment_a==1)&(errors_df.type_d==1)&(errors_df.Promo==0)].Abs_error\n",
    "groupb = errors_df[(errors_df.assortment_a==1)&(errors_df.type_a==1)&(errors_df.Promo==1)].Abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupa.mean(), groupb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(groupa, groupb, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a toy dataset with multiple features to fit a linear model and evaluate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the Boston dataset from sklearn and try to predict house prices depending on features of the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load Boston house prices data\n",
    "dt = load_boston(return_X_y=False)\n",
    "df = pd.DataFrame(data = np.c_[dt['data'],dt['target']])\n",
    "df.columns = np.append(dt['feature_names'], 'MED_VALUE')\n",
    "df.drop(['B', 'LSTAT'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features** \n",
    "\n",
    "CRIM = per capita crime rate by town  \n",
    "ZN = proportion of residential land zoned for lots over 25,000 sq.ft.  \n",
    "INDUS = proportion of non-retail business acres per town  \n",
    "CHAS = Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)  \n",
    "NOX = nitric oxides concentration (parts per 10 million)  \n",
    "RM = average number of rooms per dwelling  \n",
    "AGE = proportion of owner-occupied units built prior to 1940  \n",
    "DIS = weighted distances to five Boston employment centres  \n",
    "RAD = index of accessibility to radial highways  \n",
    "TAX = full-value property-tax rate per $10,000  \n",
    "PTRATIO = pupil-teacher ratio by town   \n",
    "\n",
    "**Target**\n",
    "\n",
    "MEDV Median value of owner-occupied homes in $1000â€™s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of model fitting with `Stats_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use formula-like strings to specify your model\n",
    "mod = smf.ols(formula='MED_VALUE ~ CRIM+ZN+INDUS+RM+DIS+PTRATIO', data=df) \n",
    "# fit\n",
    "res = mod.fit()            \n",
    "# summarize\n",
    "print(res.summary())                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aren't we forgetting an important step? \n",
    "How about some scaling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing \n",
    "\n",
    "Check if you have missing data, outliers, typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizations  \n",
    "\n",
    "The only way to understand the data. I recomend using **Plotly for Python**.  \n",
    "\n",
    "You can see some other nice plots of this dataset here: http://www.neural.cz/dataset-exploration-boston-house-pricing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Is the data ok? Then split into train and test datasets\n",
    "\n",
    "You can use `train_test_split()` from **SkLearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predict using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate error metrics\n",
    "You could use MAE and RMSE, for example. Calculate the errors of your training and test data. Is your model overfitting or underfitting?  \n",
    "\n",
    "The question you should ask now is, *is my model performing the same across all segments of my data?*   \n",
    "To answer that, separate your data into clusters (for example `CHAS`, or number of rooms `RM`) and calculate the average error and standar deviation of the error per cluster. Are they the same? Do they differ? If they differ, is this difference significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if most of the features are quantitative?  \n",
    "\n",
    "In this case you can always analyze the error per feature, with correlations, for example. Is the error maybe higher in the lower or higher ends of a given feature?  \n",
    "Another solution is to simplify and cluster the data. One solution is to use `cut()` from Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the feature `DIS`, which express distance to employement centers. Can we create maybe three bins, `SHORT`, `MEDIUM`, `LONG`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DIS.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the distance ranges from 1.13 to 12.13. We can create 3 bins in the following way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 4, 8, 13]\n",
    "labels = ['SHORT', 'MEDIUM', 'LONG']\n",
    "df['DIS_CAT'] = pd.cut(df['DIS'], bins=bins, labels=labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
